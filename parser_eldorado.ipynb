{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем библиотеки для парсинга и обработки информации\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вводится путь к вебдрайверу, который был превращен в специальный объект Service\n",
    "PATH = b\"C:\\Users\\nastya\\Desktop\\Google Chrome\\chromedriver.exe\"\n",
    "# PATH = input('Введите путь к вебдрайверу')\n",
    "service = Service(PATH)\n",
    "# запускаем браузер с помощью веб-драйвера\n",
    "browser = webdriver.Chrome(service=service)\n",
    "# открываем сайт, который будем пасрить\n",
    "browser.get('https://www.eldorado.ru/c/smartfony/')\n",
    "# дадим сайту время на прогрузку динамических элементов\n",
    "time.sleep(3)\n",
    "\n",
    "# передадим в range 35, чтоб нажать кнопку \"Показать еще\" 35 раз, если больше, то парсер будет работать часами\n",
    "for i in range(35):\n",
    "    try:\n",
    "        # находим и нажимаем кнопку \n",
    "        browser.find_element(By.CSS_SELECTOR, value='#listing-container > div.tq > button').click() \n",
    "        # немного ждем\n",
    "        time.sleep(1.5)\n",
    "    # когда такая копка исчезнет, выйдем из цикла\n",
    "    except NoSuchElementException:\n",
    "        break\n",
    "    \n",
    "# сохраним получившийся html код страницы для дальнейшей обработки\n",
    "html = browser.page_source    \n",
    "# Обработает html код с помощью BeautifulSoup и парсерса lxml \n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "# соберем элементы, где находится основная информация по телефонам,чтоб достать ссылки на индивидуальные страницы\n",
    "phones = soup.find_all('li', {'class': 'kG'})\n",
    "\n",
    "# ключами этого словаря являются названия моделей, значениями - другие словари, в которых будут хранится их характеристики\n",
    "# достаем ссылки и сразу записываем их как значения вложенного словаря, где ключом является название будущего столбца\n",
    "info = {}\n",
    "for phone in phones:\n",
    "    phone_info = phone.find('div', {'class': 'lG nG'}).a\n",
    "    info[phone_info.text] = {'link': 'https://www.eldorado.ru' + phone_info.get('href')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# переберем все ключи получившегося словаря, в котором уже есть ключ link и соответствующая ссылка\n",
    "for model in info:\n",
    "    # открываем сайт, который будем пасрить\n",
    "    browser.get(info[model]['link'])\n",
    "    # разворачиваем окно на весь экран \n",
    "    browser.fullscreen_window()\n",
    "    # # немного ждем\n",
    "    # time.sleep(1.5)\n",
    "    \n",
    "    \n",
    "    last_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "    # Скроллим вниз по странице\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        # # Ждем, пока страницы прогрузится полностью\n",
    "        # time.sleep(1.5)\n",
    "        # Считает новую высоту скроллинга (положение страницы) со старой\n",
    "        new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "        # если это конец страницы, перестает скроллить \n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "        \n",
    "    # нажимаем кнопку \"Характеристики\", чтоб увидеть все характеристики\n",
    "    try:\n",
    "        browser.find_element(By.XPATH, value='/html/body/div[11]/div[1]/div[2]/div[2]/div[4]/div/ul/li[2]/a').click()\n",
    "        # time.sleep(1.5)\n",
    "        \n",
    "    \n",
    "        # найдем таблицу со всем характеристиками и построчно будем считывать характеристики, добавляя их в словарь \n",
    "        chars_table = browser.find_element(By.XPATH, value='/html/body/div[11]/div[1]/div[2]/div[2]/div[6]/div/div[2]/table')\n",
    "        chars_rows = chars_table.find_elements(By.TAG_NAME, value='tr')\n",
    "        for char_row in chars_rows:\n",
    "            try:\n",
    "                char_info = char_row.find_elements(By.TAG_NAME, value='td')\n",
    "                char_name = char_info[0].text\n",
    "                char_value = char_info[1].text.split('\\n')[0]\n",
    "                info[model][char_name] = char_value\n",
    "            except:\n",
    "                pass\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# чтобы получился датафрейм, создаем новый словарь, \n",
    "# который будет принимать все признаки со всех моделей (они не у всех одни и те же) и проставлять пропуски там, \n",
    "# где признак у модели отсутствует, поэтому, возможно, будут столбцы с большим количеством пропусков\n",
    "res_info = {}\n",
    "for model in info:\n",
    "    res_info[model] = {}\n",
    "    for key in info[model].keys():\n",
    "        res_info[model][key] = info[model].get(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим датафрейм по получившемуся словарю и сохраним таблицу в формате csv\n",
    "df = pd.DataFrame(res_info)\n",
    "df = df.T\n",
    "df.to_csv('eldorado.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "5446dcbb0f2df12f743acade3cf2cdaf2a348c67ba351a3a9921d96789447493"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
